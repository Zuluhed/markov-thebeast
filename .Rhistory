threefactor.aov <- aov(score ~ teacher + caf + gender, data=coffeesim)
summary(threefactor.aov)
calories <- rnorm(100, 400, 150)
qplot(calories)
calories[calories < 0]
calories[calories < 0] <- 0
qplot(calories)
food.bonus <- calories * .05
qplot(calories, food.bonus)
food.bonus <- calories * .05 + rnorm(100, 0, 10)
qplot(calories, food.bonus)
coffeesim$score <- coffeesim$score + food.bonus
coffeesim$calories <- calories
head(coffeesim)
qplot(score, data=coffeesim, fill=caf, geom="density", alpha=0.5)
qplot(score, data=coffeesim, fill=teacher, geom="density", alpha=0.5)
threefactor.aov <- aov(score ~ teacher + caf + gender, data=coffeesim)
summary(threefactor.aov)
me.aov <- aov(score ~ caf + gender + teacher + Error(calories), data=coffeesim)
summary(me.aov)
qplot(calories, score)
qplot(calories, score, data=coffeesim)
rm(list=ls())
library(ggplot2)
decaf <- rep(0, 10)
caf <- rnorm(90, 100, 40)
caf <- c(caf, decaf)
qplot(caf, geom="density")
min(caf)
caf[caf < 0] <- 0
max(caf)
scores <- 65 + 0.1 * caf
qplot(caf, scores)
scores <- 65 + 0.1 * caf + rnorm(100, 0, 10)
qplot(caf, scores)
scores <- 65 + 0.1 * caf + rnorm(100, 0, 5)
qplot(caf, scores)
65 + 0.1 * caf
scores <-  rnorm(100, 65 + 0.1 * caf, 5)
qplot(caf, scores)
coffee.df <- data.frame(caf = caf, score = scores)
head(coffee.df)
coffee.glm <- glm(score ~ caf, data=coffee.df)
summary(coffee.glm)
qplot(caf, scores) + geom_abline(intercept=64.223, slope=.10233)
rpois(100, 1)
qplot(rpois(100, 1))
qplot(rpois(100, 1), geom="density")
qplot(rpois(1000, 1), geom="density")
qplot(rpois(1000, 1))
qplot(rpois(1000, 0.5))
x <- rep(seq(1, 10, by=0.2), each=100)
x
source('~/.active-rstudio-document', echo=TRUE)
y <- rpois(length(x), x)
y
qplot(x, y)
x <- rep(seq(1, 100, by=0.2), each=100)
x
y <- rpois(length(x), x)
y
qplot(x, y)
breaks <-  rpois(100, 65 + 0.1 * caf)
breaks
breaks <-  rpois(100, 1 + 0.1 * caf)
breaks
breaks <-  rpois(100, 0.1 + 0.1 * caf)
breaks
breaks <-  rpois(100, 0.01 + 0.1 * caf)
breaks
breaks <-  rpois(100, 0.1 + 0.01 * caf)
breaks
qplot(caf, breaks)
exp(.1)
breaks.glm <- glm(breaks ~ caf, family=poisson)
summary(breaks.glm)
exp(.1)
exp(-1)
exp(-100)
breaks <-  rpois(100, 0.1 + 0.01 * caf)
breaks
qplot(caf, breaks)
breaks.glm <- glm(breaks ~ caf, family=poisson)
summary(breaks.glm)
breaks <-  rpois(100, 0.1 + 0.01 * caf)
breaks
qplot(caf, breaks)
breaks.glm <- glm(breaks ~ caf, family=poisson)
summary(breaks.glm)
breaks <-  rpois(100, 0.1 + 0.01 * caf)
breaks
qplot(caf, breaks)
breaks.glm <- glm(breaks ~ caf, family=poisson)
summary(breaks.glm)
exp(-1.4)
exp(-1.5)
qplot(caf, breaks)
qplot(caf, breaks) +geom_abline(slope=.0139, intercept=-1.43)
qplot(caf, breaks) + stat_function(fun = function(x) exp(-1.45 + .0139*x))
qplot(caf, breaks) + stat_function(fun = function(x) exp( .0139*x -1.45))
x <- rbinom(n = 100, size = 10, prob = 0.5)
qplot(x)
x <- rbinom(n = 100, size = 1, prob = 0.5)
qplot(x)
awake <- rbinom(n=100, size =1, 1/(1 + 1 exp(-(5 + 5 * caf))))
1/(1 + 1 exp(-(5 + 5 * caf)))
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(5 + 5 * caf))))
plot(caf, awake)
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(.0005 + 5 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(.0005 + .05 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(.0005 + .005 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-.3 + .005 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-.3 + .05 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-.3 + .02 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-.3 + .05 * caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .1* caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .01* caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .05* caf))))
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .5* caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .1* caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .01* caf))))
qplot(caf, awake)
awake <- rbinom(n=100, size =1, 1/(1 + exp(-(-3 + .05* caf))))
qplot(caf, awake)
awake.glm <- glm(awake~caf, family="binomial")
summary(awake.glm)
qplot(caf, awake) + stat_function(fun = function(x) 1/(1 + exp(-(-1.8 + .039*caf))))
dim(awake)
length(awake)
length(caf)
qplot(caf, breaks) + stat_function(fun = function(x) exp( .0139*x -1.45))
qplot(caf, awake) + stat_function(fun = function(x) 1/(1 + exp(-(-1.8 + .039*caf))))
qplot(caf, awake)
1/(1 + exp(-(-1.8 + .039*caf)))
qplot(caf, awake) + stat_function(fun = function(x) 1/(1 + exp(-(-1.8 + .039*x))))
awake
breaks
scores <- rnorm(100, 65 + (0.1 * caf) + (5 *  awake) + (-2 * breaks), 5)
scores
qplot(caf, scores)
qplot(awake, scores)
qplot(breaks, scores)
new.glm <- glm(scores ~ caf + awake + breaks, family="gaussian")
summary(new.glm)
scores <- rnorm(100, 65 + (0.1 * caf) + (5 *  awake) + (-2 * breaks), 20)
qplot(caf, scores)
qplot(awake, scores)
qplot(breaks, scores)
new.glm <- glm(scores ~ caf + awake + breaks, family="gaussian")
summary(new.glm)
scores <- rnorm(100, 65 + (0.1 * caf) + (5 *  awake) + (-2 * breaks), 10)
qplot(caf, scores)
qplot(awake, scores)
qplot(breaks, scores)
new.glm <- glm(scores ~ caf + awake + breaks, family="gaussian")
summary(new.glm)
teacher <- c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J")
teacher.effect <- rnorm(10, 0, 10)
teacher.effect
teacher <- rep(teacher, 10)
teacher.effect <- rep(teacher.effect, 10)
teacher.diff <- rnorm(100, teacher.effect, 5)
teacher.diff
coffee.df <- data.frame(caf = caf, score=score + teacher.diff, awake=awake,
breaks=breaks, teacher=teacher)
coffee.df <- data.frame(caf = caf, score=scores + teacher.diff, awake=awake,
breaks=breaks, teacher=teacher)
head(coffee.df)
qplot(score, data=coffee.df, fill=teacher, geom="density", alpha=0.5)
qplot(caf, score, data=coffee.df)
no.me.glm <- glm(score ~ caf + awake + breaks, family="gaussian")
no.me.glm <- glm(score ~ caf + awake + breaks, data=coffee.df, family="gaussian")
summary(no.me.glm)
library(lme4)
library(lmerTest)
coffee.lme <- lmer(score ~ coffee + awake + breaks + (1|teacher), data=coffee.df)
coffee.lme <- lmer(score ~ caf + awake + breaks + (1|teacher), data=coffee.df)
summary(coffee.lme)
library(rwty)
help(rwty)
both.evenodd <- function(x, y){
if(x %% 2 == 0 && y %% 2 == 0){
print("both even")
}
else {
print("both odd")
}
}
both.evenodd(1,2)
library(devtools)
help(devtools)
install_github("emoGG")
install_github("emoGG", "dill")
library(emoGG)
qplot(Sepal.Length, Sepal.Width, data=iris)
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="1f337")
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="u2615")
help(emoji_search)
emoji_search("coffee")
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="\u2615")
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="1307")
help(gg_emoji)
help(geom_emoji)
help(emoji_search)
emojis()
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="coffee")
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="cafe")
qplot(Sepal.Length, Sepal.Width, data=iris) + geom_emoji(emoji="2615")
help(geom_emoji)
qplot(Sepal.Length, Sepal.Width, data=iris) + add_emoji(emoji="2615")
library(plyr)
help(ddply)
library(maps)
library(dismo)
map('world', regions='australia')
map.axes()
aus.extent <- extent(112, 156, -45, -9.5)
prot <- gbif("grevillea", ext=aus.extent, geo=TRUE, sp=TRUE)
dim(prot)
grev <- gbif("grevillea baueri", ext=aus.extent, geo=TRUE, sp=TRUE)
grev <- gbif("grevillea", spcies="baueri", geo=TRUE, sp=TRUE)
grev <- gbif("grevillea", species="baueri", geo=TRUE, sp=TRUE)
grev <- gbif("grevillea", species="baueri", geo=TRUE)
head(grev)
all.aus <- gbif(ext=aus.extent, geo=TRUE)
all.aus <- gbif(genus = "*", ext=aus.extent, geo=TRUE)
library(rgbif)
install.packages("rgbif")
library(rgbif)
aus.code <- isocodes[grep("Australia", isocodes$name), "code"]
aus.code
occ_count(country=aus.code)
occ_count(country=aus.code, georeferenced=TRUE)
occ_search(country=aus.code, limit=100)
occ_search(country=aus.code, limit=10000)
name_backbone(kingdom="Plantae")
name_backbone(name="Plantae", rank="kingdom")
plants <- (name_lookup(query='plantae', return = 'data'))
head(plants)
tail(plants)
plants <- (name_lookup(query='plantae', rank="kingdom", return = 'data'))
plants
occ_search(country=aus.code, limit=10000)
occ_count(country=aus.code, year=2015, georeferenced=TRUE)
occ_count(country=aus.code, year=2014, georeferenced=TRUE)
occ_count(country=aus.code,  georeferenced=TRUE)
occ_count(country=aus.code,  year="2014", georeferenced=TRUE)
help(occ_count)
occ_count(country=aus.code, from=2000, georeferenced=TRUE)
occ_count(country=aus.code, from=2013, georeferenced=TRUE)
occ_count(country=aus.code, from=2013, to=2014, georeferenced=TRUE)
occ_count(country=aus.code, from=1970, to=1980, georeferenced=TRUE)
help)occ_search
help(occ_search)
occ_search(country=aus.code, limit=500)
# holy.txt contains the centuries of nostradamus, the egyptian book of the dead,
# revelations, and liber logaeth, which is apparently a chunk of the necronomicon
setwd("~/GitHub/markov-thebeast")
library(ngram)
library(twitteR)
library(tm)
library(tm.plugin.webmining)
googlenews <- WebCorpus(GoogleNewsSource("Microsoft"))
googlenews.in <- paste(unlist(lapply(googlenews$content, function(x) x$content)), collapse = " ")
googlenews.in <- gsub("\\n", " ", googlenews.in)
googlenews.in <- gsub("([\\])", " ", googlenews.in)
yahoonews <- WebCorpus(YahooNewsSource("Microsoft"))
yahoonews.in <- paste(unlist(lapply(yahoonews$content, function(x) x$content)), collapse = " ")
yahoonews.in <- gsub("\\n", " ", yahoonews.in)
yahoonews.in <- gsub("([\\])", " ", yahoonews.in)
# options(httr_oauth_cache=T)
#
# apikey <- "ff6Jf9V7epy27yMbNJuDVvJun"
# apisecret <- "Jzgju26tWFvoOjpKf6TiSsYgqWjHWOUQe4nKVmcCsBIg4VL5zu"
# token <- "4837743903-demnJz0lwa5DHQqnoqOx04DNRiXPBys4WFqB3HY"
# tokensecret <- "cDloocuGYiNwIlfaUJuqu5A5HptxBjY3r7vNPFfzpytgc"
# setup_twitter_oauth(apikey, apisecret, token, tokensecret)
infile <- file("holy.txt")
holy.in <- readLines(infile)
holy.in <- paste(holy.in, collapse=" ")
# Haven't grabbed anybody's tweets yet, but that could be fun.  Maybe top trending on twitter?
# infile2 <- file("palintweets.txt")
# tweets.in <- readLines(infile2)
# Should I have it do appends?  Maybe add some religious twits
# appends <- file("palinappends.txt")
# appends.in <- readLines(appends)
# holy.in <- c(holy.in, tweets.in)
holy.in <- paste(holy.in, googlenews.in, yahoonews.in, collapse = " ")
beast.ngram <- ngram(holy.in, 2)
while(1){
print(1)
beast.babble <- babble(beast.ngram)
print(2)
write(beast.babble, file="log.txt")
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", beast.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(beast.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
# De-comment this once I add appends
# if(nchar(this.sentence) <= 100){
#    this.sentence <- paste(this.sentence, sample(appends.in, 1))
# }
sentences <- c(sentences, this.sentence)
}
}
if(length(sentences < 1)){
out.sentence <- sample(sentences, 1)
print(out.sentence)
# tweet(out.sentence)
}
Sys.sleep(10)
}
while(1){
print(1)
beast.babble <- babble(beast.ngram)
print(2)
write(beast.babble, file="log.txt")
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", beast.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(beast.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
# De-comment this once I add appends
# if(nchar(this.sentence) <= 100){
#    this.sentence <- paste(this.sentence, sample(appends.in, 1))
# }
sentences <- c(sentences, this.sentence)
}
}
out.sentence <- NULL
if(length(sentences) > 1){
out.sentence <- sample(sentences, 1)
}
else{
out.sentence <- sentences[1]
}
print(out.sentence)
# tweet(out.sentence)
Sys.sleep(10)
}
options(httr_oauth_cache=T)
apikey <- "Sur0VwituHxoPSgQqwMynwgnh"
apisecret <- "aQVNgaqC6IIoUqAmDTYBqbJydrGYvkRNJzEHLRxoSb8mM2I5nK"
token <- "4890065174-4GGBq3nV50EOPSQTqHAORmJX66c0QhY1va2V2Fj"
tokensecret <- "H3qGjsNyQSVBPQ9BQaC8SOOYol6ypCG5v43qtVyOGGsyw"
setup_twitter_oauth(apikey, apisecret, token, tokensecret)
help(getTrends)
getTrends
getTrends()
availableTrendLocations()
getTrends(1)
availableTrendLocations()
availableTrendLocations()$name
getTrends(461)
getTrends(23424977)
help(getTrends)
for(i in 1:nrow(trends)){
thistag <- trends[i, 1]
print(thistag)
}
tweets <- c()
trends <- getTrends(23424977)
for(i in 1:nrow(trends)){
thistag <- trends[i, 1]
print(thistag)
}
searchTwitter("#NBArank")
help(searchTwitter)
nrow(trends)
searchTwitter("#NBArank", 500)
# Grab trends table from USA
tweets <- c()
trends <- getTrends(23424977)
for(i in 1:3){
thistag <- trends[i, 1]
these.tweets <- searchTwitter(thistag, 500)
these.tweets <- paste(twListToDF(these.tweets)$text, collapse = " ")
print(these.tweets)
tweets <- c(tweets, these.tweets)
}
tweets
tweets <- gsub("http[^[:space:]]*", "", tweets)
tweets
length(tweets)
tweets <- c()
trends <- getTrends(23424977)
for(i in 1:3){
thistag <- trends[i, 1]
print("Harvesting tag", i, ":", thistag)
these.tweets <- searchTwitter(thistag, 500)
these.tweets <- paste(twListToDF(these.tweets)$text, collapse = " ")
tweets <- paste(tweets, these.tweets, collapse = " ")
}
tweets <- gsub("http[^[:space:]]*", "", tweets)
tweets <- gsub("\\n", " ", tweets)
# Grab trends table from USA
tweets <- c()
trends <- getTrends(23424977)
for(i in 1:3){
thistag <- trends[i, 1]
print(paste("Harvesting tag", i, ":", thistag))
these.tweets <- searchTwitter(thistag, 500)
these.tweets <- paste(twListToDF(these.tweets)$text, collapse = " ")
tweets <- paste(tweets, these.tweets, collapse = " ")
}
tweets <- gsub("http[^[:space:]]*", "", tweets)
tweets <- gsub("\\n", " ", tweets)
# Grab trends table from USA
tweets <- c()
trends <- getTrends(23424977)
for(i in 1:nrow(trends)){
thistag <- trends[i, 1]
print(paste("Harvesting tag", i, ":", thistag))
these.tweets <- searchTwitter(thistag, 500)
these.tweets <- paste(twListToDF(these.tweets)$text, collapse = " ")
tweets <- paste(tweets, these.tweets, collapse = " ")
}
tweets <- gsub("http[^[:space:]]*", "", tweets)
tweets <- gsub("\\n", " ", tweets)
tweets
tweets <- gsub("([\\])", " ", tweets)
nchar(tweets)
nchar(holy.in)
holy.in <- paste(holy.in, googlenews.in, yahoonews.in, tweets, collapse = " ")
beast.ngram <- ngram(holy.in, 2)
while(1){
beast.babble <- babble(beast.ngram)
write(beast.babble, file="log.txt")
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", beast.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(beast.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
# De-comment this once I add appends
# if(nchar(this.sentence) <= 100){
#    this.sentence <- paste(this.sentence, sample(appends.in, 1))
# }
sentences <- c(sentences, this.sentence)
}
}
out.sentence <- NULL
if(length(sentences) > 1){
out.sentence <- sample(sentences, 1)
}
else{
out.sentence <- sentences[1]
}
print(out.sentence)
# tweet(out.sentence)
Sys.sleep(10)
}
beast.ngram <- ngram(holy.in, 2)
while(1){
beast.babble <- babble(beast.ngram)
write(beast.babble, file="log.txt")
# Break out sentences
sentences <- c()
sentence.starts <- as.vector(gregexpr("[?.!] +[A-Z]", beast.babble)[[1]])
for(i in 1:(length(sentence.starts) - 1)){
this.sentence <- substr(beast.babble, sentence.starts[i]+2, sentence.starts[i+1])
if(nchar(this.sentence) <= 140){
# De-comment this once I add appends
# if(nchar(this.sentence) <= 100){
#    this.sentence <- paste(this.sentence, sample(appends.in, 1))
# }
sentences <- c(sentences, this.sentence)
}
}
out.sentence <- NULL
if(length(sentences) > 1){
out.sentence <- sample(sentences, 1)
}
else{
out.sentence <- sentences[1]
}
print(out.sentence)
# tweet(out.sentence)
Sys.sleep(10)
}
holy.in
tweets <- gsub("([\\])", " ", tweets)
tweets
tweets <- paste(tweets, collapse=" ")
tweets <- gsub("http[^[:space:]]*", "", tweets)
tweets <- gsub("\\n", " ", tweets)
tweets <- gsub("([\\])", " ", tweets)
tweets
holy.in <- paste(holy.in, googlenews.in, yahoonews.in, tweets, collapse = " ")
tweets <- gsub("([\"])", " ", tweets)
tweets
infile <- file("holy.txt")
holy.in <- paste(holy.in, collapse=" ")
holy.in <- readLines(infile)
holy.in <- paste(holy.in, googlenews.in, yahoonews.in, tweets, collapse = " ")
dim(holy.in)
rm(list=ls())
